<!DOCTYPE html>
<html>
<head>
    <title>Study Alarm</title>
    <style>
        body {
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-image: url("background_image.jpg"); /* Replace "background_image.jpg" with the path to your background image */
            background-size: cover;
        }

        .container {
            text-align: center;
            background-color: rgba(255, 255, 255, 0.8); /* Set the desired background color and opacity */
            padding: 20px;
        }

        #webcam-container {
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Study Alarm</h1>
        <button type="button" onclick="startCamera()">CAM</button>
        <button type="button" onclick="startProgram()">Start</button>
        <div id="webcam-container"></div>
        <div id="label-container"></div>
        <button type="button" onclick="stopProgram()">Stop</button>
        <div id="timer">00:00:00</div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/posenet"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest"></script>
    <script type="text/javascript">
        const URL = "./my_model/";

        let model, webcam, labelContainer, maxPredictions;

        // Start the webcam
        async function startCamera() {
            const flip = true;
            webcam = new tmImage.Webcam(200, 200, flip);
            await webcam.setup();
            webcam.play();
            requestAnimationFrame(loop);

            document.getElementById("webcam-container").appendChild(webcam.canvas);
        }

        // Load the image model
        async function loadModel() {
            const modelURL = URL + "model.json";
            const metadataURL = URL + "metadata.json";

            model = await tmImage.load(modelURL, metadataURL);
            maxPredictions = model.getTotalClasses();

            labelContainer = document.getElementById("label-container");
            for (let i = 0; i < maxPredictions; i++) {
                const labelDiv = document.createElement("div");
                labelContainer.appendChild(labelDiv);
            }
        }

        // Start the prediction loop
        async function startPrediction() {
            await predict();
            requestAnimationFrame(startPrediction);
        }

        async function predict() {
            const prediction = await model.predict(webcam.canvas);
              if (prediction[0].className == "뜬눈" && prediction[0].probability.toFixed(2) == 1.00) {
            labelContainer.childNodes[0].innerHTML = `뜬눈: ${prediction[0].probability.toFixed(2)}`;}
            else if (prediction[1].className == "감은눈" && prediction[1].probability.toFixed(2) == 1.00) {
            labelContainer.childNodes[1].innerHTML = `감은눈: ${prediction[1].probability.toFixed(2)}`;}
        }

        function startProgram() {
            loadModel();
            playSoundAndStart();
        }

        function playSoundAndStart() {
            const studySound = new Audio("study_sound.mp3"); // Replace with the path to your study sound file
            studySound.play();
        }

        function stopProgram() {
            webcam.stop();
            const studySound = new Audio("study_sound.mp3"); // Replace with the path to your study sound file
            studySound.pause();
        }
    </script>
</body>
</html>
