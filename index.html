<!DOCTYPE html>
<html>
<head>
    <title>Study Alarm</title>
    <style>
        body {
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-image: url("background_image.jpg"); /* Replace "background_image.jpg" with the path to your background image */
            background-size: cover;
        }
        
        .container {
            text-align: center;
            background-color: rgba(255, 255, 255, 0.8); /* Set the desired background color and opacity */
            padding: 20px;
        }
        
        #webcam-container {
            margin-bottom: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>Study Alarm</h1>
        <div id="webcam-container"></div>
        <div id="label-container"></div>
        <button type="button" onclick="startProgram()">Start</button>
        <button type="button" onclick="stopProgram()">Stop</button>
        <div id="timer">00:00:00</div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/knn-classifier"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/handpose"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/facemesh"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/pose"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image"></script>
    <script type="text/javascript">

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
    <script type="text/javascript">
    // More API functions here:
    // https://github.com/googlecreativelab/teachablemachine-community/tree/master/libraries/pose

    // the link to your model provided by Teachable Machine export panel
    const URL = "./my_model/";
    const studySound = new Audio("study_sound.mp3"); // Replace "study_sound.mp3" with the path to your study sound file
    const breakSound = new Audio("break_sound.mp3");
    let alarmSound = new Audio("alarm_sound.mp3"); // Replace "alarm_sound.mp3" with the path to your alarm sound file
    let alarmTimer;
    let model, webcam, labelContainer, maxPredictions;
    let timer;
    let studyInterval;
    let breakInterval;
    let studyCount = 0;
    let isStudyTime = false;
    let isBreakTime = false;
   
    // Load the image model and setup the webcam
    async function init() {
        const modelURL = URL + "model.json";
        const metadataURL = URL + "metadata.json";

        // load the model and metadata
        // Refer to tmImage.loadFromFiles() in the API to support files from a file picker
        // or files from your local hard drive
        // Note: the pose library adds "tmImage" object to your window (window.tmImage)
        model = await tmImage.load(modelURL, metadataURL);
        maxPredictions = model.getTotalClasses();

        // Convenience function to setup a webcam
        const flip = true; // whether to flip the webcam
        webcam = new tmImage.Webcam(400, 400, flip); // width, height, flip
        await webcam.setup(); // request access to the webcam
        await webcam.play();
        window.requestAnimationFrame(loop);

        // append elements to the DOM
        document.getElementById("webcam-container").appendChild(webcam.canvas);
        labelContainer = document.getElementById("label-container");
        for (let i = 0; i < maxPredictions; i++) { // and class labels
            labelContainer.appendChild(document.createElement("div"));
        }
    }

    async function loop() {
        webcam.update(); // update the webcam frame
        await predict();
        window.requestAnimationFrame(loop);
    }

    function startProgram() {
        clearInterval(studyInterval);
        clearInterval(breakInterval);
        studySound.play(); // Play the study sound
        studyCount = 0;
        isStudyTime = true;
        timer = setTimeout(startBreak, 2400000); // 40 minutes study time
        timer = setTimeout(startStudy, 600000); // 10 minutes break time
        studyInterval = setInterval(checkEyes, 1000);
    }

    function startBreak() {
        clearTimeout(timer);
        isStudyTime = false;
        isBreakTime = true;
        timer = setTimeout(startBreak, 2400000); // 40 minutes study time
        timer = setTimeout(startStudy, 600000); // 10 minutes break time
        breakInterval = setInterval(displayBreakMessage, 1000);
        breakSound.play(); // Play the break sound
    }

    function startStudy() {
        clearTimeout(timer);
        isStudyTime = true;
        isBreakTime = false;
        studyCount++;
        if (studyCount >= 5) {
            clearInterval(studyInterval);
            clearInterval(breakInterval);
            displayEndMessage();
            return;
        }
        studySound.play();
        timer = setTimeout(startBreak, 2400000); // 40 minutes study time
        timer = setTimeout(startStudy, 600000); // 10 minutes break time
        studyInterval = setInterval(checkEyes, 1000);
    }

    function displayBreakMessage() {
    const minutes = Math.floor(timer / 60000);
    const seconds = Math.floor((timer % 60000) / 1000);
    console.log(`Break Time: ${minutes} minutes ${seconds} seconds remaining`);
}
    function checkEyes() {
    if (!isStudyTime) return;

    const prediction = model.predict(webcam.canvas);
    const closedEyesProbability = prediction[1].probability.toFixed(2);

    if (closedEyesProbability === "1.00") {
        if (timer) clearTimeout(timer); // Clear the previous timer if it exists
        timer = setTimeout(alertUser, 20000); // Alert after 20 seconds of closed eyes
    } else {
        clearTimeout(timer);
        timer = null;
    }
}

function alertUser() {
    if (isBreakTime) {
        console.log("Alert: 일어나세요~");
        return;
    }
    alarmSound.play();
    alarmTimer = setTimeout(stopAlarm, 30000);
    // Play the alert sound or trigger any desired notification
    console.log("Alert: 일어나세요~");
}
function stopAlarm() {
    alarmSound.pause();
    alarmSound.currentTime = 0;
}

const breakButton = document.getElementById("break-button");
breakButton.addEventListener("click", takeBreak);
function takeBreak() {
    clearTimeout(timer);
    clearInterval(studyInterval);
    clearInterval(breakInterval);
    isStudyTime = false;
    isBreakTime = true;

    startBreak();
}
    // run the webcam image through the image model
async function predict() {
        // predict can take in an image, video or canvas html element
    const prediction = await model.predict(webcam.canvas);
        for (let i = 0; i < maxPredictions; i++) {
            const classPrediction =
                prediction[i].className + ": " + prediction[i].probability.toFixed(2);
            labelContainer.childNodes[i].innerHTML = classPrediction;
        }
    
    if(prediction[0].className=="뜬눈"&&prediction[0].probability.toFixed(2)==1.00)
    {
        labelContainer.childNodes[0].innerHTML="뜬눈"
    }
    else if(prediction[1].className=="감은눈"&&prediction[1].probability.toFixed(2)==1.00)
    {
        labelContainer.childNodes[1].innerHTML="감은눈"
    }
    
    
}
</script>




</body>
</html>
